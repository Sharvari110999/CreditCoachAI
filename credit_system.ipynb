{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemma:2b-instruct\"\n",
    "DB_NAME = \"vector_db\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for RAG pipeline\n",
    "\n",
    "import glob\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 markdown files from data folder\n"
     ]
    }
   ],
   "source": [
    "# Load all markdown files from data folder\n",
    "\n",
    "markdown_files = glob.glob(\"data/*.md\")\n",
    "\n",
    "documents = []\n",
    "\n",
    "for file_path in markdown_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        documents.append({\"content\": content, \"source\": file_path})\n",
    "\n",
    "print(f\"Loaded {len(documents)} markdown files from data folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old DB deleted.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(DB_NAME):\n",
    "    shutil.rmtree(DB_NAME)\n",
    "    print(\"Old DB deleted.\")\n",
    "else:\n",
    "    print(\"No existing DB found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 189 chunks from 16 documents\n"
     ]
    }
   ],
   "source": [
    "# Split documents into chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "for doc in documents:\n",
    "    doc_chunks = text_splitter.create_documents(\n",
    "        texts=[doc[\"content\"]],\n",
    "        metadatas=[{\"source\": doc[\"source\"]}]\n",
    "    )\n",
    "    chunks.extend(doc_chunks)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DB created successfully.\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=DB_NAME\n",
    "    )\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "print(\"New DB created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OllamaLLM(temperature=0, model=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"\n",
    "You are a strict intent classifier.\n",
    "\n",
    "Classify the user query into EXACTLY one of these labels:\n",
    "\n",
    "explanation\n",
    "advisory\n",
    "risk_assessment\n",
    "simulation\n",
    "\n",
    "Label meanings:\n",
    "\n",
    "explanation = asking to define or explain something.\n",
    "advisory = asking what action to take OR how to do something.\n",
    "risk_assessment = asking if something is bad, harmful, or risky.\n",
    "simulation = describing a specific hypothetical situation and asking what will happen.\n",
    "\n",
    "Rules:\n",
    "- Output ONLY one label.\n",
    "- No extra words.\n",
    "- No punctuation.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_LABELS = {\n",
    "    \"explanation\",\n",
    "    \"advisory\",\n",
    "    \"risk_assessment\",\n",
    "    \"simulation\"\n",
    "}\n",
    "\n",
    "def classify_intent(question: str):\n",
    "    q = question.lower().strip()\n",
    "\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=SYSTEM_PROMPT_TEMPLATE),\n",
    "        HumanMessage(content=question)\n",
    "    ])\n",
    "    \n",
    "    label = response.strip().lower()\n",
    "    \n",
    "    if label not in ALLOWED_LABELS:\n",
    "        return \"explanation\"  \n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(question: str):\n",
    "\n",
    "    intent = classify_intent(question)\n",
    "    context = retrieve_context(question)\n",
    "\n",
    "    if intent == \"explanation\":\n",
    "        return handle_explanation(question, context)\n",
    "        \n",
    "    elif intent == \"advisory\":\n",
    "        return handle_advisory(question, context)\n",
    "        \n",
    "    elif intent == \"risk_assessment\":\n",
    "        return handle_risk_assessment(question, context)\n",
    "        \n",
    "    elif intent == \"simulation\":\n",
    "        return handle_simulation(question, context)\n",
    "\n",
    "    return intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(question: str, k: int = 4):\n",
    "    docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_explanation(question: str, context: str):\n",
    "    prompt = f\"\"\"\n",
    "    You are a UK credit education assistant.\n",
    "\n",
    "    Use the verified knowledge base context below as your primary source.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Provide a structured explanation:\n",
    "\n",
    "    - Clear Definition\n",
    "    - Why It Matters\n",
    "    - Practical Example (if relevant)\n",
    "\n",
    "    Do NOT invent statistics or exact credit score numbers.\n",
    "    If context does not contain the answer, say so clearly.\n",
    "    \"\"\"\n",
    "\n",
    "    return llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_risk_assessment(question: str, context: str):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a UK credit risk assessment engine.\n",
    "\n",
    "    Use the following verified UK credit knowledge base context:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    The user question is:\n",
    "    {question}\n",
    "\n",
    "    You will Estimate the following\n",
    "    Risk Level:\n",
    "    Baseline Reason: \n",
    "\n",
    "    Your task:\n",
    "    - Validate or adjust the risk level if necessary.\n",
    "    - Provide clear reasoning grounded in UK credit principles.\n",
    "    - Do NOT invent numerical score changes.\n",
    "    - Keep explanation concise and practical.\n",
    "\n",
    "    Provide output in this format:\n",
    "\n",
    "    - Risk Level (Low / Medium / High)\n",
    "    - Why This Is Risky\n",
    "    - Time Sensitivity (Immediate / Short-Term / Long-Term)\n",
    "    - Recommended Precaution (1â€“2 steps)\n",
    "    \"\"\"\n",
    "\n",
    "    return llm.invoke(prompt)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_advisory(question: str, context: str):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a UK credit advisor.\n",
    "\n",
    "    Use the following verified UK credit information:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Format:\n",
    "    - Goal\n",
    "    - 3 Action Steps\n",
    "    - 1 Warning\n",
    "    \"\"\"\n",
    "\n",
    "    return llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_simulation(question: str, context: str):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a UK credit system simulation engine.\n",
    "\n",
    "    Use the following verified UK credit knowledge base context:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    The user is asking a what-if scenario.\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Provide structured output in this format:\n",
    "\n",
    "    - Scenario Summary\n",
    "    - Short-Term Impact (0â€“3 months)\n",
    "    - Medium-Term Impact (3â€“12 months)\n",
    "    - Estimated Risk Level (Low / Medium / High)\n",
    "    - Recovery Strategy (3 steps)\n",
    "    - Key Insight\n",
    "\n",
    "    Use realistic UK principles.\n",
    "    Do NOT hallucinate exact credit score numbers.\n",
    "    \"\"\"\n",
    "\n",
    "    return llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_LABELS = {\n",
    "    \"explanation\",\n",
    "    \"advisory\",\n",
    "    \"risk_assessment\",\n",
    "    \"simulation\"\n",
    "}\n",
    "\n",
    "def classify_intent(question: str):\n",
    "    q = question.lower().strip()\n",
    "\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=SYSTEM_PROMPT_TEMPLATE),\n",
    "        HumanMessage(content=question)\n",
    "    ])\n",
    "    \n",
    "    label = response.strip().lower()\n",
    "    \n",
    "    if label not in ALLOWED_LABELS:\n",
    "        return \"explanation\"  \n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(question: str):\n",
    "\n",
    "    intent = classify_intent(question)\n",
    "\n",
    "    context, confidence = retrieve_context(question, intent)\n",
    "\n",
    "    decision = decide_execution(intent, confidence)\n",
    "\n",
    "    print(f\"[Intent: {intent}] [Confidence: {confidence:.3f}] [Decision: {decision}]\")\n",
    "\n",
    "    if decision == \"local\":\n",
    "\n",
    "        if intent == \"explanation\":\n",
    "            return handle_explanation(question, context)\n",
    "        \n",
    "        elif intent == \"advisory\":\n",
    "            return handle_advisory(question, context)\n",
    "        \n",
    "        elif intent == \"risk_assessment\":\n",
    "            return handle_risk_assessment(question, context)\n",
    "        \n",
    "        elif intent == \"simulation\":\n",
    "            return handle_simulation(question, context)\n",
    "\n",
    "    else:\n",
    "        print(\" Escalating to Gemini (Cloud) \")\n",
    "        return handle_cloud_execution(question, intent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(question: str, intent: str):\n",
    "    \n",
    "    # Category-aware k\n",
    "    if intent == \"simulation\":\n",
    "        k = 8\n",
    "    elif intent == \"explanation\":\n",
    "        k = 6\n",
    "    else:\n",
    "        k = 4\n",
    "\n",
    "    # Get docs with similarity scores\n",
    "    docs_with_scores = vectorstore.similarity_search_with_score(question, k=k)\n",
    "\n",
    "    docs = [doc for doc, score in docs_with_scores]\n",
    "    scores = [score for doc, score in docs_with_scores]\n",
    "\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # Confidence = inverse of distance (Chroma returns distance, lower is better)\n",
    "    # Convert to similarity-style confidence\n",
    "    if scores:\n",
    "        confidence = max(0, 1 - scores[0])  # top match confidence\n",
    "    else:\n",
    "        confidence = 0\n",
    "\n",
    "    return context, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_execution(intent: str, confidence: float):\n",
    "    \n",
    "    # Simple initial logic\n",
    "    if confidence < 0.55:\n",
    "        return \"cloud\"\n",
    "    \n",
    "    # Simulation queries require higher confidence\n",
    "    if intent == \"simulation\" and confidence < 0.65:\n",
    "        return \"cloud\"\n",
    "    \n",
    "    return \"local\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_cloud_execution(question: str, intent: str):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert UK credit advisor.\n",
    "\n",
    "    The local system had low retrieval confidence.\n",
    "    Provide a structured answer for this intent: {intent}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Follow the same structured format used by the system.\n",
    "    Do NOT fabricate exact score numbers.\n",
    "    \"\"\"\n",
    "\n",
    "    response = gemini_llm.invoke(prompt)\n",
    "\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sharv\\OneDrive\\Desktop\\CreditSystem\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sharv\\OneDrive\\Desktop\\CreditSystem\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Intent: simulation] [Confidence: -0.024] [Decision: cloud]\n",
      " Escalating to Gemini (Cloud) \n",
      "**Structured Answer: AI-Based Risk Models in UK Banks**\n",
      "\n",
      "AI-based risk models are sophisticated tools employed by UK banks to enhance the accuracy, efficiency, and speed of risk assessment across various domains. They leverage advanced computational techniques to analyse vast datasets, providing deeper insights into potential risks than traditional methods.\n",
      "\n",
      "**1. Core Purpose & Evolution:**\n",
      "*   **Enhanced Risk Assessment:** Moving beyond traditional statistical models, AI provides more granular and dynamic risk profiling across credit, market, operational, and fraud risks.\n",
      "*   **Proactive Management:** Enables banks to identify emerging risks and opportunities earlier, facilitating more timely interventions and strategic decision-making.\n",
      "*   **Regulatory Compliance:** Supports adherence to stringent UK and international financial regulations (e.g., PRA, FCA, Basel III, IFRS 9).\n",
      "\n",
      "**2. Key Data Sources Utilised:**\n",
      "*   **Traditional Credit Data:**\n",
      "    *   **Credit Bureau Reports:** Comprehensive data from agencies like Experian, Equifax, and TransUnion, detailing credit history, payment behaviour, and existing credit facilities.\n",
      "    *   **Internal Bank Data:** Transaction history, account balances, loan repayment records, savings patterns, and customer demographics.\n",
      "    *   **Application Data:** Information provided by applicants, including income, employment status, residential history, and declared assets/liabilities.\n",
      "*   **Alternative & Non-Traditional Data (with explicit consent):**\n",
      "    *   **Open Banking Data:** Categorised transaction data from other financial institutions, providing a holistic view of income and expenditure, affordability, and financial stability.\n",
      "    *   **Publicly Available Data:** Electoral roll information, Companies House data (for business lending), and property registers.\n",
      "    *   **Digital Footprint Data:** Used cautiously and ethically, primarily for fraud detection or specific niche products, always with explicit customer consent and robust privacy safeguards.\n",
      "\n",
      "**3. AI/Machine Learning Techniques Employed:**\n",
      "*   **Supervised Learning:**\n",
      "    *   **Classification Models:** Logistic Regression, Decision Trees, Random Forests, and Gradient Boosting Machines (e.g., XGBoost, LightGBM) are widely used to predict the probability of default (PD), identify fraudulent activities, or classify customers into distinct risk segments.\n",
      "    *   **Regression Models:** Employed for predicting financial metrics such as loss given default (LGD) or exposure at default (EAD).\n",
      "*   **Unsupervised Learning:**\n",
      "    *   **Clustering:** Techniques like K-means or hierarchical clustering are used for customer segmentation, identifying distinct risk profiles, or uncovering hidden behavioural groups within a portfolio.\n",
      "    *   **Anomaly Detection:** Algorithms such as Isolation Forests or One-Class SVMs are crucial for identifying unusual patterns indicative of fraud, money laundering, or operational anomalies.\n",
      "*   **Natural Language Processing (NLP):** Analysing unstructured text data from customer interactions, complaints, news articles, or legal documents to assess sentiment, identify emerging risks, or improve customer service and compliance.\n",
      "*   **Deep Learning (Neural Networks):** Increasingly applied for complex pattern recognition, particularly in advanced fraud detection, image analysis (e.g., document verification), or processing large, unstructured datasets, often balanced with the need for explainability.\n",
      "\n",
      "**4. Applications in UK Banking:**\n",
      "*   **Credit Risk Assessment:**\n",
      "    *   Automated and dynamic credit scoring for personal loans, mortgages, credit cards, and business lending.\n",
      "    *   Continuous risk monitoring of existing loan portfolios.\n",
      "    *   Early warning systems for identifying deteriorating credit quality or potential defaults.\n",
      "*   **Fraud Detection & Prevention:**\n",
      "    *   Real-time transaction monitoring to flag suspicious activities and prevent financial crime.\n",
      "    *   Sophisticated application fraud detection to prevent identity theft and misrepresentation.\n",
      "*   **Market Risk Management:**\n",
      "    *   Predicting market volatility and asset price movements.\n",
      "    *   Conducting stress testing on portfolios under various adverse economic scenarios.\n",
      "*   **Operational Risk Management:**\n",
      "    *   Identifying potential system failures, process inefficiencies, or human errors.\n",
      "    *   Predicting compliance breaches and regulatory non-adherence.\n",
      "*   **Customer Behaviour & Personalisation:**\n",
      "    *   Predicting customer churn and identifying opportunities for retention.\n",
      "    *   Tailoring product offerings, pricing, and marketing strategies based on individual risk profiles and preferences.\n",
      "\n",
      "**5. Key Considerations & Challenges (UK Context):**\n",
      "*   **Explainability (XAI):** UK regulators (PRA, FCA) place a strong emphasis on understanding *why* an AI model made a particular decision, especially for adverse credit outcomes. This often necessitates the use of more interpretable models or advanced explainability techniques (e.g., SHAP, LIME) to provide clear justifications.\n",
      "*   **Bias & Fairness:** Ensuring models do not inadvertently discriminate against protected characteristics (as per the Equality Act 2010). Regular auditing, bias detection, and mitigation strategies are critical to ensure ethical and fair outcomes.\n",
      "*   **Data Privacy & Security:** Strict adherence to GDPR and the Data Protection Act 2018 is paramount, requiring robust data governance, anonymisation, secure storage, and transparent consent mechanisms for customer data.\n",
      "*   **Model Governance:** UK banks must establish comprehensive frameworks for model development, independent validation, ongoing monitoring, and regular re-calibration to ensure models remain accurate, robust, and fit for purpose throughout their lifecycle.\n",
      "*   **Data Quality:** The effectiveness of AI models is heavily reliant on the quality, completeness, and relevance of the input data. \"Garbage in, garbage out\" remains a fundamental principle.\n",
      "*   **Dynamic Environment:** Models require continuous monitoring and retraining to adapt to evolving economic conditions, regulatory changes, and shifts in customer behaviours and fraud patterns.\n",
      "\n",
      "By integrating these advanced AI capabilities, UK banks aim to build more resilient, efficient, and customer-centric financial services while navigating a complex and evolving regulatory landscape.\n"
     ]
    }
   ],
   "source": [
    "print(route_question(\"How do AI-based risk models in UK banks work?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
